# Custom PrometheusRule for home-lab
# Namespace: monitoring
#
# Story: 4.4 - Configure Alertmanager with Alert Rules
# FR: FR28 - System sends alerts via Alertmanager when thresholds exceeded
# NFR: NFR5 - Alertmanager sends P1 alerts within 1 minute of threshold breach
#
# Custom alert rules for home-lab specific services:
# - PostgreSQL database availability (P1)
# - NFS storage provisioner availability (P1)
# - OpenClaw CrashLoopBackOff (P2) - Story 21.4, NFR102
---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: home-lab-custom-alerts
  namespace: monitoring
  labels:
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/part-of: home-lab
    prometheus: kube-prometheus-stack-prometheus  # Required for auto-discovery
    release: kube-prometheus-stack
spec:
  groups:
    - name: home-lab-custom.rules
      interval: 30s  # Evaluate every 30 seconds to meet NFR5 (P1 alerts within 1 minute)
      rules:
        # PostgreSQL Unhealthy Alert (P1)
        - alert: PostgreSQLUnhealthy
          expr: |
            kube_deployment_status_replicas_available{deployment="postgresql", namespace="data"} == 0
            or
            absent(kube_deployment_status_replicas_available{deployment="postgresql", namespace="data"})
          for: 0s  # Fire immediately - no pending period for P1
          labels:
            severity: critical
            component: database
            service: postgresql
            priority: P1
          annotations:
            summary: "PostgreSQL database unavailable"
            description: "PostgreSQL deployment in namespace 'data' has no available replicas. Database is unavailable."
            runbook_url: "https://github.com/yourusername/home-lab/blob/main/docs/runbooks/postgresql-recovery.md"
            impact: "All applications depending on PostgreSQL database will fail"
            action: "Check PostgreSQL pod status, logs, and PVC availability. Verify NFS connectivity."

        # NFS Provisioner Unreachable Alert (P1)
        - alert: NFSProvisionerUnreachable
          expr: |
            kube_deployment_status_replicas_available{deployment="nfs-provisioner-nfs-subdir-external-provisioner", namespace="infra"} == 0
            or
            absent(kube_deployment_status_replicas_available{deployment="nfs-provisioner-nfs-subdir-external-provisioner", namespace="infra"})
          for: 0s  # Fire immediately - no pending period for P1
          labels:
            severity: critical
            component: storage
            service: nfs-provisioner
            priority: P1
          annotations:
            summary: "NFS storage provisioner unreachable"
            description: "NFS subdir external provisioner in namespace 'infra' has no available replicas. Dynamic PVC provisioning is unavailable."
            runbook_url: "https://github.com/yourusername/home-lab/blob/main/docs/runbooks/nfs-recovery.md"
            impact: "New PVC requests will fail. Stateful workloads cannot scale or restart successfully."
            action: "Check NFS provisioner pod status, logs, and Synology NFS export accessibility. Verify network connectivity to Synology."

        # vLLM GPU Inference Unavailable Alert (P2 - Informational)
        # Story: 13.3 - Integrate n8n Fallback Routing
        # FR: FR98 - Gaming Mode enables CPU fallback
        # AC: #4 - Degraded Mode Alerting
        - alert: VLLMGPUUnavailable
          expr: |
            kube_deployment_status_replicas_available{deployment="vllm-server", namespace="ml"} == 0
          for: 30s  # Wait 30s to avoid alerting during normal mode transitions
          labels:
            severity: warning
            component: ml-inference
            service: vllm
            priority: P2
          annotations:
            summary: "GPU unavailable - using CPU fallback"
            description: "vLLM GPU inference is unavailable. AI workflows are using Ollama CPU fallback with degraded performance."
            runbook_url: "https://github.com/tjetzinger/home-lab/blob/main/docs/runbooks/egpu-hotplug.md"
            impact: "AI inference latency increased. Using CPU-only Ollama with smaller models."
            action: "If gaming, this is expected. Otherwise run 'gpu-mode ml' on k3s-gpu-worker to restore GPU inference."

        # OpenClaw CrashLoopBackOff Alert (P2)
        # Story: 21.4 - Enable Telegram Channel with DM Security
        # NFR: NFR102 - Alertmanager sends notification within 2 minutes of CrashLoopBackOff
        # Note: Built-in KubePodCrashLooping fires after 15 min; this custom rule meets the 2-min requirement.
        - alert: OpenclawCrashLooping
          expr: |
            kube_pod_container_status_waiting_reason{reason="CrashLoopBackOff", namespace="apps", pod=~"openclaw.*"} > 0
          for: 2m
          labels:
            severity: warning
            component: ai-gateway
            service: openclaw
            priority: P2
          annotations:
            summary: "OpenClaw pod is in CrashLoopBackOff"
            description: "OpenClaw pod {{ $labels.pod }} in namespace 'apps' has been in CrashLoopBackOff for more than 2 minutes."
            impact: "Telegram channel, Control UI, and LLM routing are unavailable."
            action: "Check pod logs: kubectl logs -n apps {{ $labels.pod }} --previous. Check openclaw.json for invalid config keys."
