# vLLM Service for home-lab
# Namespace: ml
#
# Story: 12.4 - Deploy vLLM with 3-Model Configuration
# FR: FR38 - Deploy vLLM for production inference
# AC: #2 - Create Service and IngressRoute
#
# Exposes vLLM OpenAI-compatible API on port 8000
---
apiVersion: v1
kind: Service
metadata:
  name: vllm-api
  namespace: ml
  labels:
    app.kubernetes.io/name: vllm
    app.kubernetes.io/instance: vllm-api
    app.kubernetes.io/part-of: home-lab
    app.kubernetes.io/component: llm-inference
spec:
  type: ClusterIP
  selector:
    app: vllm-server
  ports:
    - name: http
      port: 8000
      targetPort: 8000
      protocol: TCP
