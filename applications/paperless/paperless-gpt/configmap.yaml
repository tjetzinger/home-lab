# Paperless-GPT ConfigMap for home-lab
# Namespace: docs
#
# Story: 25.4 - Deploy Paperless-GPT and Remove Paperless-AI
# Story: 26.2 - Update Service Default Models to Cloud Tier
# Epic: 25 - Document Processing Pipeline Upgrade
# Epic: 26 - Ollama Pro Cloud Model Integration
#
# FRs:
# - FR192: Paperless-GPT deployed with Docling OCR provider
# - FR193: Docling integration for two-stage document processing
# - FR194: LiteLLM integration for LLM-based metadata generation
# - FR197: Manual review (paperless-gpt tag) and automatic processing (paperless-gpt-auto tag)
# - FR219: Paperless-GPT uses cloud-minimax for document metadata generation (Story 26.2)
#
# NFRs:
# - NFR112: Prompt template changes take effect without pod restart
# - NFR121: Document processing completes within 60s timeout
#
# Environment Variables Reference:
# https://github.com/icereed/paperless-gpt
apiVersion: v1
kind: ConfigMap
metadata:
  name: paperless-gpt-config
  namespace: docs
  labels:
    app.kubernetes.io/name: paperless-gpt
    app.kubernetes.io/instance: paperless-gpt
    app.kubernetes.io/part-of: home-lab
    app.kubernetes.io/component: document-ai
    app.kubernetes.io/managed-by: kubectl
data:
  # Paperless-ngx connection
  # Service DNS: paperless-paperless-ngx.docs.svc.cluster.local:8000
  PAPERLESS_BASE_URL: "http://paperless-paperless-ngx.docs.svc.cluster.local:8000"

  # OCR Provider - Docling (Story 25.3)
  # Service DNS: docling.docs.svc.cluster.local:5001
  # Mode: whole_pdf with skip — Paperless-ngx already OCR's on ingest,
  # so Docling detects existing text layer and skips re-processing (~50% faster)
  OCR_PROVIDER: "docling"
  DOCLING_URL: "http://docling.docs.svc.cluster.local:5001"
  DOCLING_OCR_PIPELINE: "standard"
  DOCLING_OCR_ENGINE: "easyocr"
  OCR_PROCESS_MODE: "whole_pdf"
  PDF_SKIP_EXISTING_OCR: "true"

  # LLM Provider - LiteLLM (OpenAI-compatible proxy)
  # Cloud-tier primary: cloud-minimax (Ollama Pro) with LiteLLM fallback chain
  # Fallback: cloud-minimax → vllm-qwen (GPU) → ollama-qwen (CPU)
  # Service DNS: litellm.ml.svc.cluster.local:4000
  LLM_PROVIDER: "openai"
  OPENAI_BASE_URL: "http://litellm.ml.svc.cluster.local:4000/v1"
  LLM_MODEL: "cloud-minimax"
  LLM_LANGUAGE: "German"

  # Tag-based workflow triggers
  MANUAL_TAG: "paperless-gpt"
  AUTO_TAG: "paperless-gpt-auto"

  # Auto-generation toggles (all enabled for full metadata extraction)
  AUTO_GENERATE_TITLE: "true"
  AUTO_GENERATE_TAGS: "true"
  AUTO_GENERATE_CORRESPONDENTS: "true"
  AUTO_GENERATE_CREATED_DATE: "true"
  AUTO_GENERATE_DOCUMENT_TYPE: "true"

  # System
  LOG_LEVEL: "info"
